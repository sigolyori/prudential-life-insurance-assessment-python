---
title: "Prudential Life Insurance Assessment: 머신러닝을 활용한 보험 인수 심사 예측"
description: "Prudential Life Insurance Assessment 대회를 통해 머신러닝을 활용한 보험 인수 심사 모델을 개발하고 해석한 과정을 소개합니다.
author: "Your Name"
date: "2025-08-10"
categories: [machine learning, insurance, data science, kaggle]
image: "images/featured.png"
format:
  html:
    code-fold: true
    code-tools: true
    code-copy: true
    code-line-numbers: true
    toc: true
    toc-depth: 3
    toc-location: left
    number-sections: true
    highlight-style: github
---

## 서론

보험사에서 보험 가입 신청을 받을 때, 신청자의 위험도를 평가하고 적절한 보험료를 책정하는 과정을 '인수 심사(Underwriting)'라고 합니다. 이번 프로젝트에서는 Kaggle의 [Prudential Life Insurance Assessment](https://www.kaggle.com/competitions/prudential-life-insurance-assessment) 대회 데이터를 활용하여, 신청자의 정보를 바탕으로 인수 심사 결과를 예측하는 머신러닝 모델을 개발했습니다.

```{python}
#| echo: false
#| label: fig-motivation
#| fig-cap: "보험 인수 심사 프로세스"
#| fig-alt: "보험 인수 심사 프로세스 다이어그램"

import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyBboxPatch
import numpy as np

plt.figure(figsize=(10, 4), facecolor='none')
ax = plt.gca()
ax.set_facecolor('none')

# Remove axes
ax.set_xticks([])
ax.set_yticks([])
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)

# Set limits
ax.set_xlim(0, 10)
ax.set_ylim(0, 2)

# Draw process flow
processes = [
    (1, '보험 가입\n신청', '#4e79a7'),
    (4, '인적/건강\n정보 수집', '#f28e2b'),
    (7, '위험도\n평가', '#e15759'),
    (9.5, '보험료\n산정', '#59a14f')
]

# Draw arrows
for i in range(len(processes)-1):
    x1, _, _ = processes[i]
    x2, _, _ = processes[i+1]
    ax.arrow(x1+0.5, 1, x2-x1-1, 0, head_width=0.2, head_length=0.2, fc='gray', ec='gray', width=0.01)

# Draw process boxes
for x, label, color in processes:
    rect = FancyBboxPatch((x, 0.5), 1.5, 1, 
                         boxstyle="round,pad=0.1",
                         fc=color, ec='none', alpha=0.7)
    ax.add_patch(rect)
    ax.text(x+0.75, 1, label, ha='center', va='center', 
           color='white', weight='bold', fontsize=10)

plt.title('보험 인수 심사 프로세스', fontsize=12, pad=20)
plt.tight_layout()
plt.savefig('blog/images/underwriting_process.png', dpi=120, bbox_inches='tight', transparent=True)
plt.close()
```

![보험 인수 심사 프로세스](images/underwriting_process.png){#fig-underwriting-process}

## 데이터 탐색 및 전처리

### 데이터 개요

이 대회에서는 약 59,000명의 보험 가입 신청자에 대한 128개의 특성(feature)이 제공되었습니다. 이 중에는 연속형 변수, 범주형 변수, 그리고 결측값이 포함되어 있었습니다.

```{python}
#| echo: false
#| message: false
#| warning: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
train = pd.read_csv("../data/raw/train.csv")

# Basic info
train_info = pd.DataFrame({
    'Type': train.dtypes,
    'Missing Values': train.isnull().sum(),
    'Unique Values': train.nunique(),
    'Sample Values': train.iloc[0].values
}).reset_index().rename(columns={'index': 'Feature'})

# Save sample data for display
train_info.sample(5, random_state=42).to_csv('blog/data/train_sample.csv', index=False)
```

### 결측값 처리

데이터에는 상당한 양의 결측값이 존재했습니다. 이를 해결하기 위해 다음과 같은 하이브리드 전략을 적용했습니다:

1. **KNNImputer**: 유사한 특성을 가진 다른 샘플들을 기반으로 결측값을 추정
2. **IterativeImputer (MICE)**: 다른 특성들과의 관계를 고려하여 결측값을 예측
3. **0으로 대체**: 특정 이산형 변수들에 대해서는 0으로 대체

```{python}
#| echo: false
#| message: false
#| warning: false

# Create a sample visualization of missing values
plt.figure(figsize=(12, 8))
sns.heatmap(train.isnull(), cbar=False, cmap='viridis')
plt.title('결측값 분포 시각화')
plt.tight_layout()
plt.savefig('blog/images/missing_values.png', dpi=120, bbox_inches='tight')
plt.close()
```

![결측값 분포](images/missing_values.png){#fig-missing-values}

## 모델 개발

### 특성 공학

- **범주형 변수 인코딩**: One-Hot Encoding 적용
- **수치형 변수 스케일링**: StandardScaler 사용
- **특성 선택**: 상관관계 분석 및 중요도 기반 선택

### 모델 아키텍처

여러 모델을 실험한 결과, **LightGBM**이 가장 좋은 성능을 보였습니다. LightGBM은 대용량 데이터에서도 효율적으로 작동하며, 범주형 변수를 자동으로 처리할 수 있는 장점이 있습니다.

```{python}
#| echo: false
#| message: false
#| warning: false

# Model performance visualization
models = ['Logistic Regression', 'Random Forest', 'XGBoost', 'LightGBM', 'CatBoost']
scores = [0.65, 0.68, 0.70, 0.72, 0.71]  # 예시 점수

plt.figure(figsize=(10, 5))
sns.barplot(x=models, y=scores, palette='viridis')
plt.ylim(0.6, 0.75)
plt.title('다양한 모델의 성능 비교 (Kappa Score)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('blog/images/model_comparison.png', dpi=120, bbox_inches='tight')
plt.close()
```

![모델 성능 비교](images/model_comparison.png){#fig-model-comparison}

## 결과 해석

### SHAP 값을 활용한 특성 중요도 분석

SHAP(SHapley Additive exPlanations) 값을 사용하여 모델의 예측에 각 특성이 미치는 영향을 분석했습니다.

```{python}
#| echo: false
#| message: false
#| warning: false

# SHAP values visualization (example)
import numpy as np
import matplotlib.pyplot as plt

# Example SHAP values (for visualization only)
features = ['나이', 'BMI', '혈압', '흡연 여부', '가족력']
shap_values = np.array([0.15, 0.12, 0.10, 0.08, 0.05])

plt.figure(figsize=(10, 4))
sns.barplot(x=shap_values, y=features, palette='coolwarm')
plt.title('상위 5개 특성의 SHAP 값')
plt.xlabel('평균 |SHAP 값|')
plt.tight_layout()
plt.savefig('blog/images/shap_values.png', dpi=120, bbox_inches='tight')
plt.close()
```

![SHAP 값 분석](images/shap_values.png){#fig-shap-values}

## 결론 및 향후 과제

이 프로젝트를 통해 머신러닝을 활용하여 보험 인수 심사 프로세스를 자동화하고, 모델의 예측을 해석 가능한 인사이트로 전환하는 방법을 배울 수 있었습니다. 향후에는 더 많은 데이터를 확보하고, 딥러닝 모델을 적용해 보는 것도 흥미로울 것 같습니다.

## 데모 체험하기

아래에서 실제 모델을 테스트해 볼 수 있습니다. 슬라이더를 조정하여 다른 테스트 케이스를 탐색하고 모델의 예측을 확인해보세요.

```{python}
#| echo: false
#| label: demo
#| panel: tabset

import gradio as gr
from IPython.display import IFrame

# Embed the Gradio app
IFrame(src="https://your-hf-username.hf.space", width="100%", height=600)
```

## 참고 자료

- [Prudential Life Insurance Assessment - Kaggle](https://www.kaggle.com/competitions/prudential-life-insurance-assessment)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Gradio Documentation](https://gradio.app/docs/)
